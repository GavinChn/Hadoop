在eclipse中写MapReduce时eclipse版本要新，不然报错(null) entry in command string: null chmod 0700
关系型数据库和MapReduce的比较
					传统关系型数据库					MapReduce
数据大小				GB									PB
访问				交互型和批处理						批处理
更新				多次读写							一次写入多次读取	
结构				静态模型							动态模型	
集成度					高									低				
伸缩性				非线性									线性
MapReduce的工作分为map阶段和reduce阶段，每个阶段都有键/值作为输入和输出。
Map函数功能是提取数据，将其作为输出发送。Map函数的输出先由MapReduce框架处理（对键/值进行排序和分组），然后发送到Reduce函数
Map函数有一个Mapper接口实现
Reduce函数有一个Reducer接口实现
HDFS架构
Block：一个文件分块，默认64M
Namenode：保存整个文件系统的目录信息，文件信息以及文件相应的分块信息。
DataNode：用于存储Blocks
HDFS的HA策略：NameNode一旦宕机，整个文件系统将无法工作。
				如果NameNode中的数据丢失，整个文件系统也就丢失了。
				2.x开始，HDFS支持NameNode的active-standy模式
NameNode HA：支持NameNode的active-standy模式
HDFS Federation：支持多个NameNode，分担数据压力


Centos7 ssh免登陆配置之后要修改权限
Shell代码:   chmod 700 ~/.ssh
            chmod 600 ~/.ssh/authorized_keys
出现warning: mv ~/.ssh/known_hosts /tmp
密钥传给分节点之后执行：ssh-add
需要关闭防火墙：
在 CentOS 6.x 中，可以通过如下命令关闭防火墙：
sudo service iptables stop   # 关闭防火墙服务
sudo chkconfig iptables off  # 禁止防火墙开机自启，就不用手动关闭了
若用是 CentOS 7，需通过如下命令关闭（防火墙服务改成了 firewall）：
systemctl stop firewalld.service    # 关闭firewall
systemctl disable firewalld.service # 禁止firewall开机启动
格式化之前：sudo chmod -R a+w /usr/Hadoop
启动前：修改/etc/hadoop/hadoop-env.sh中设JAVA_HOME。
export JAVA_HOME=/usr/java/jdk1.6.0_45        //正确，应该这么改
export HADOOP_CONF_DIR=/usr/Hadoop/etc/Hadoop
这里hbase也是要配置的conf/ hbase-env.sh
配置zookeeper时：sudo mv /usr/zookeeper/myid /usr/zookeeper/tmp/zookeeper/myid

start-all.sh
start-dfs.sh
start-yarn.sh
mr-jobhistory-daemon.sh start historyserver网页显示Hadoop状态

stop-all.sh
stop-yarn.sh
stop-dfs.sh
mr-jobhistory-daemon.sh stop historyserver 

hadoop dfsadmin -safemode leave取消安全模式

start-hbase.sh
stop-hbase.sh
hbase shell

hive
hive --service hiveserver2开始监听端口默认10000
hive --service metastore
关于hive：
1.hive 是否需要每个datanode都安装？
2. <property>
    <name>hive.metastore.uris</name>
    <value>uri1,uri2,... </value>//可配置多个 uri    
    <description>JDBC connect string for a JDBC metastore</description>
    </property>
这个配置的含义是什么？
3.当在Hadoop的HA环境中Hive Server安装在哪里比较合适？
4.每个DataNode上都已经安装了Hbase，是否都要安装Hive?
第1问回答：Hive的安装其实有两部分组成，一个是Server端、一个是客户端，所谓服务端其实就是Hive管理Meta的那个Hive,服务端可以装在任何节点上，可以是Namenode上也可以是Datanode的任意一个节点上，至于哪个节点做Hive的服务端，由自己决定，不过在Hadoop的HA环境里我想应该是在两个NameNode里都装成Hive的Server，并且hive.metastore.warehouse.dir 配置成hdfs://****，这样其他节点安装的Hive就都是客户端了，并且hive.metastore.uris值可以指向这两个NameNode的Ip.（仅代表个人理解，如果有不对的地方请多多指教）

主要属性解释：
hive.metastore.uris：指定hive元数据访问路径
hive.metastore.warehouse.dir：（HDFS上的）数据目录
hive.exec.scratchdir：（HDFS上的）临时文件目录
hive.metastore.warehouse.dir默认值是/user/hive/warehouse
hive.exec.scratchdir默认值是/tmp/hive-${user.name}

第2问回答：这个属性都配置在客户端，ip地址指向的是Hive服务端Ip地址，端口是默认的。 可以看到value可以指向多个ip，意思应该是多个Hive Server所在主机。（仅代表个人理解，不吝赐教）

第3问回答：个人认为安装在NameNode所在节点（假如集群有两个NameNode,那么两个NameNode都要安装）。

第4问回答：其实根据前面问题的回答，这个问题已经不需解释，这个问题的底层意思应该是说Hive数据的存储问题，比如Hbase在每个节点上都部署了，并且存储会根据数据的分裂存储在各个Datanode上，那么是不是没有安装Hive的DataNode上就无法存储Hive的数据？其实，Hive数据的存储是根据hive.metastore.warehouse.dir这个属性来配置，这个属性加入制定的是HDFS集群，那么Hive数据的存储已经指向了所有的DataNode了。

解决亚马逊API问题：http://www.aboutyun.com/thread-14501-1-1.html

hadoop fs -ls -R：可查看目录。
hadoop fs -rmr output:干掉输出文件。

重复格式化namenode需要将缓存清空/Hadoop/tmp/dfs
netstat -nlp | grep java查看进程,然后kill -9 

GRANT ALL PRIVILEGES ON *.* TO 'cheng'@'192.168.209.131' IDENTIFIED BY 'cheng' WITH GRANT OPTION;mysql授权
flush privileges;刷新权限

HDFS命令基本格式：hadoop fs -cmd < args >

ls 命令

hadoop fs -ls  /
列出hdfs文件系统根目录下的目录和文件

hadoop fs -ls -R /
列出hdfs文件系统所有的目录和文件

put 命令

hadoop fs -put < local file > < hdfs file >
hdfs file的父目录一定要存在，否则命令不会执行

hadoop fs -put  < local file or dir >...< hdfs dir >
hdfs dir 一定要存在，否则命令不会执行

hadoop fs -put - < hdsf  file>
从键盘读取输入到hdfs file中，按Ctrl+D结束输入，hdfs file不能存在，否则命令不会执行

moveFromLocal 命令

hadoop fs -moveFromLocal  < local src > ... < hdfs dst >
与put相类似，命令执行后源文件 local src 被删除，也可以从从键盘读取输入到hdfs file中

copyFromLocal 命令

hadoop fs -copyFromLocal  < local src > ... < hdfs dst >
与put相类似，也可以从从键盘读取输入到hdfs file中

get 命令

hadoop fs -get < hdfs file > < local file or dir>
local file不能和 hdfs file名字不能相同，否则会提示文件已存在，没有重名的文件会复制到本地

hadoop fs -get < hdfs file or dir > ... < local  dir >
拷贝多个文件或目录到本地时，本地要为文件夹路径 
注意：如果用户不是root， local 路径要为用户文件夹下的路径，否则会出现权限问题，

moveToLocal 命令

当前版本中还未实现此命令

copyToLocal 命令

hadoop fs -copyToLocal < local src > ... < hdfs dst >
与get相类似

rm 命令

hadoop fs -rm < hdfs file > ...
hadoop fs -rm -r < hdfs dir>...
每次可以删除多个文件或目录

mkdir 命令

hadoop fs -mkdir < hdfs path>
只能一级一级的建目录，父目录不存在的话使用这个命令会报错

hadoop fs -mkdir -p < hdfs path> 
所创建的目录如果父目录不存在就创建该父目录

getmerge 命令

hadoop fs -getmerge < hdfs dir >  < local file >
将hdfs指定目录下所有文件排序后合并到local指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容

hadoop fs -getmerge -nl  < hdfs dir >  < local file >
加上nl后，合并到local file中的hdfs文件之间会空出一行

cp 命令

hadoop fs -cp  < hdfs file >  < hdfs file >
目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件还存在

hadoop fs -cp < hdfs file or dir >... < hdfs dir >
目标文件夹要存在，否则命令不能执行

mv 命令

hadoop fs -mv < hdfs file >  < hdfs file >
目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件不存在

hadoop fs -mv  < hdfs file or dir >...  < hdfs dir >
源路径有多个时，目标路径必须为目录，且必须存在。 
注意：跨文件系统的移动（local到hdfs或者反过来）都是不允许的

count 命令

hadoop fs -count < hdfs path >
统计hdfs对应路径下的目录个数，文件个数，文件总计大小 
显示为目录个数，文件个数，文件总计大小，输入路径

du 命令

hadoop fs -du < hdsf path> 
显示hdfs对应路径下每个文件夹和文件的大小

hadoop fs -du -s < hdsf path> 
显示hdfs对应路径下所有文件和的大小

hadoop fs -du - h < hdsf path> 
显示hdfs对应路径下每个文件夹和文件的大小,文件的大小用方便阅读的形式表示，例如用64M代替67108864

text 命令

hadoop fs -text < hdsf file>
将文本文件或某些格式的非文本文件通过文本格式输出

setrep 命令

hadoop fs -setrep -R 3 < hdfs path >
改变一个文件在hdfs中的副本个数，上述命令中数字3为所设置的副本个数，-R选项可以对一个人目录下的所有目录+文件递归执行改变副本个数的操作

stat 命令

hdoop fs -stat [format] < hdfs path >
返回对应路径的状态信息

[format]可选参数有：%b（文件大小），%o（Block大小），%n（文件名），%r（副本个数），%y（最后一次修改日期和时间）

可以这样书写hadoop fs -stat %b%o%n < hdfs path >，不过不建议，这样每个字符输出的结果不是太容易分清楚
tail 命令

hadoop fs -tail < hdfs file >
在标准输出中显示文件末尾的1KB数据

archive 命令

hadoop archive -archiveName name.har -p < hdfs parent dir > < src >* < hdfs dst >
命令中参数name：压缩文件名，自己任意取； 
< hdfs parent dir > ：压缩文件所在的父目录； 
< src >：要压缩的文件名； 
< hdfs dst >：压缩文件存放路径

*示例：hadoop archive -archiveName hadoop.har -p /user 1.txt 2.txt /des 
示例中将hdfs中/user目录下的文件1.txt，2.txt压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下，如果1.txt，2.txt不写就是将/user目录下所有的目录和文件压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下
显示har的内容可以用如下命令：

hadoop fs -ls /des/hadoop.jar
显示har压缩的是那些文件可以用如下命令

hadoop fs -ls -R har:///des/hadoop.har
注意：har文件不能进行二次压缩。如果想给.har加文件，只能找到原来的文件，重新创建一个。har文件中原来文件的数据并没有变化，har文件真正的作用是减少NameNode和DataNode过多的空间浪费。

balancer 命令

hdfs balancer
如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程

dfsadmin 命令

hdfs dfsadmin -help
管理员可以通过dfsadmin管理HDFS，用法可以通过上述命令查看

hdfs dfsadmin -report
显示文件系统的基本数据

hdfs dfsadmin -safemode < enter | leave | get | wait >
enter：进入安全模式；leave：离开安全模式；get：获知是否开启安全模式； 
wait：等待离开安全模式
distcp 命令

用来在两个HDFS之间拷贝数据

Hive启动失败
若启动不成功，则会出现以下错误：
 
则需要进入到hadoop安装目录下的share/hadoop/yarn/lib下删除jline-0.9.94.jar文件，再启动hive即可（因为高版本的Hadoop对Hive有捆绑）。
rpm -qa|grep mysql卸载系统原有的mysql安装包
rpm –qa查看已安装软件
rpm -ql 软件名称  显示路径

Hadoop删除退役节点：
参数作用:
dfs.hosts:
dfs.hosts.exclude:
它们的本质作用 是 拒绝某些节点上的datanode进程连接， 而不是 调度这些节点上datanode进程的允许和关闭。
用法说明：
修改conf/mapred-site.xml，添加：
<property>
    <name>dfs.hosts</name>
    <value>/opt/hadoop/conf/datanode-allow.list</value>
  </property>
  <property>
    <name>dfs.hosts.exclude</name>
    <value>/opt/hadoop/conf/datanode-deny.list</value>
  </property>

balance工具通常用于平衡hadoop集群中各datanode中的文件块分布
start-balancer.sh [-threshold <threshold>]  
stop-balancer.sh   
-threshold 默认设置：10，参数取值范围：0-100设定标准阈值

dfs.name.dir
这个参数用于确定将HDFS文件系统的元信息保存在什么目录下。
如果这个参数设置为多个目录，那么这些目录下都保存着元信息的多个备份。
<property>
    <name>dfs.name.dir</name>
    <value>/pvdata/hadoopdata/name/,/opt/hadoopdata/name/</value>
</property>

http://wenku.baidu.com/link?url=57W2TLfztl0V6DjnhWrryKiR9UmFgu-VXa7Rqy6e9r0qx8p42Vm6U2tPcx-fWCoVRK9XoCMURIoTFX2T1NHTiI3qNuo7qPFkbQ2xWHfRceG
http://wenku.baidu.com/link?url=Enp2BqBs8VLuqHxRN2VZgfFJ7TbyX-7QH7AigTCzhRqjI_WABqq-LUzdQP4zCKcNA0Eyi26Ua8sP9I3JzC0hFk8xW-AF9kek-oAE1NqLWVW
http://blog.chinaunix.net/uid-20593827-id-4042244.html
http://www.tuicool.com/articles/Nz63Ynb
http://www.mamicode.com/info-detail-503994.html  mysql安装
http://www.aboutyun.com/thread-8629-1-1.html  http://www.aboutyun.com/thread-6697-1-1.html	impala
http://blog.csdn.net/linlinv3/article/details/49512587 hive部署
http://blog.csdn.net/lifuxiangcaohui/article/details/40588929 hive倒入方式
http://www.aboutyun.com/thread-12279-1-1.html	hive远程
http://itindex.net/detail/51373-hbase-完全  hbase完全分布式安装与配置


